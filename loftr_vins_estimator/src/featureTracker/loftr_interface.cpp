#include "loftr_interface.h"
#include "loftr_onnx.h"
#include "loftr_tensorrt.h"
#include <iostream>
#include <chrono> // for time consumption
#include <algorithm>
#include <fstream> // For file I/O

LoFTR_Interface::LoFTR_Interface() 
    : initialized_(false), active_backend_(BackendType::AUTO), 
      total_matches_(0), scale_factor_(1.0f) {
}

// Interallgence pinter will automatacally release source
LoFTR_Interface::~LoFTR_Interface() {
}

// 1. Initial function
/*
1. Input:config
2. Output:bool(sueecss or not)
*/
bool LoFTR_Interface::initialize(const Config& config) {
    config_ = config;
    network_input_size_ = cv::Size(config_.input_width, config_.input_height);
    
    std::cout << "[LoFTR] Start Initialize..." << std::endl;
    std::cout << "[LoFTR] Input Size: " << config_.input_width << "x" << config_.input_height << std::endl;
    std::cout << "[LoFTR] Matching Threshold: " << config_.match_threshold << std::endl;
    
    // é€‰æ‹©åç«¯
    if (config_.backend == BackendType::AUTO) {
        active_backend_ = selectBestBackend();
    } else {
        active_backend_ = config_.backend;
    }
    
    bool success = false;
    
    // initialized according to the chosened backend
    switch (active_backend_) {
        case BackendType::TENSORRT:
            std::cout << "[LoFTR] start TensorRT backend..." << std::endl;
            try {
                tensorrt_backend_ = std::make_unique<LoFTR_TensorRT>();
                success = tensorrt_backend_->initialize(config_.model_path, config_.engine_path,
                                                       config_.input_width, config_.input_height);
                if (success) {
                    std::cout << "[LoFTR] TensorRT successed" << std::endl;
                } else {
                    std::cout << "[LoFTR] TensorRT failedï¼Œtry ONNX Runtime..." << std::endl;
                    tensorrt_backend_.reset();
                    active_backend_ = BackendType::ONNX_RUNTIME;
                }
            } catch (const std::exception& e) {
                std::cout << "[LoFTR] TensorRT error: " << e.what() << std::endl;
                tensorrt_backend_.reset();
                active_backend_ = BackendType::ONNX_RUNTIME;
            }
            break;
            
        case BackendType::ONNX_RUNTIME:
            // å¦‚æœ TensorRT å¤±è´¥ï¼Œå°è¯• ONNX Runtime
            success = false;
            break;
            
        case BackendType::AUTO:
            // ğŸ”§ ä¿®å¤ï¼šå¤„ç†AUTOæšä¸¾å€¼
            // è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºä¸Šé¢å·²ç»è½¬æ¢äº†
            std::cout << "[LoFTR] Auto backend already selected" << std::endl;
            success = false;
            break;
    }
    
    // å¦‚æœ TensorRT å¤±è´¥ï¼Œæˆ–è€…ç›´æ¥é€‰æ‹©äº† ONNX Runtime
    if (!success && active_backend_ == BackendType::ONNX_RUNTIME) {
        std::cout << "[LoFTR] initialized ONNX Runtime backend..." << std::endl;
        try {
            onnx_backend_ = std::make_unique<LoFTR_ONNX>();
            success = onnx_backend_->initialize(config_.model_path, config_.input_width, config_.input_height);
            if (success) {
                std::cout << "[LoFTR] ONNX Runtime initialized success" << std::endl;
            } else {
                std::cout << "[LoFTR] ONNX Runtime initilized failed" << std::endl;
            }
        } catch (const std::exception& e) {
            std::cout << "[LoFTR] ONNX Runtime error: " << e.what() << std::endl;
            onnx_backend_.reset();
        }
    }
    
    initialized_ = success;
    
    if (initialized_) {
        std::cout << "[LoFTR] initialized success " << getBackendInfo() << std::endl;
        resetStats();
    } else {
        std::cout << "[LoFTR] initialized failed" << std::endl;
    }
    
    return initialized_;
}


// 2. Start matching function
/*
1. Input: img0 img1
2. Output:Match result(keypoints0, keypoints1, confidence, num_matches, inference_time_ms)
*/
LoFTR_Interface::MatchResult LoFTR_Interface::match_images(const cv::Mat& img0, const cv::Mat& img1) {
    MatchResult result;
    
    if (!initialized_) {
        std::cerr << "[LoFTR] error:Not initilized" << std::endl;
        return result;
    }
    
    if (img0.empty() || img1.empty()) {
        std::cerr << "[LoFTR] error:input image is empty" << std::endl;
        return result;
    }
    // 1.pre_process, 2.inference, 3.post_process time
    auto start_time = std::chrono::high_resolution_clock::now();
    
    try {
        // Pre_process Image
        cv::Mat processed_img0 = preprocessImage(img0);
        cv::Mat processed_img1 = preprocessImage(img1);
        
        // Inference according to the backend(trt or onnx)
        bool inference_success = false;
        std::vector<float> raw_output;
        
        if (active_backend_ == BackendType::TENSORRT && tensorrt_backend_) {
            inference_success = tensorrt_backend_->infer(processed_img0, processed_img1, raw_output);
        } else if (active_backend_ == BackendType::ONNX_RUNTIME && onnx_backend_) {
            inference_success = onnx_backend_->infer(processed_img0, processed_img1, raw_output);
        }
        
        // Post_process result
        if (inference_success) {
            
            result = postprocessMatches(raw_output, img0.size(), img1.size());
            
            auto end_time = std::chrono::high_resolution_clock::now();
            result.inference_time_ms = std::chrono::duration<double, std::milli>(end_time - start_time).count();
            
            // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            inference_times_.push_back(result.inference_time_ms);
            total_matches_++;
            
            std::cout << "[LoFTR] Matching Finished: " << result.num_matches << " pair matching, "
                      << "time: " << result.inference_time_ms << " ms" << std::endl;
        } else {
            std::cerr << "[LoFTR] Inference failed" << std::endl;
        }
        
    } catch (const std::exception& e) {
        std::cerr << "[LoFTR] matching error: " << e.what() << std::endl;
    }
    
    return result;
}

// 3. Select the backend automatically
LoFTR_Interface::BackendType LoFTR_Interface::selectBestBackend() {
    std::cout << "[LoFTR] auto select the best backend..." << std::endl;
    
    // Firse is TensorRT
    try {
        auto test_tensorrt = std::make_unique<LoFTR_TensorRT>();
        if (test_tensorrt->isAvailable()) {
            std::cout << "[LoFTR]  TensorRT supported" << std::endl;
            return BackendType::TENSORRT;
        }
    } catch (...) {
        // TensorRT ä¸å¯ç”¨
    }
    
    // å›é€€åˆ° ONNX Runtime
    std::cout << "[LoFTR] Back to ONNX Runtime" << std::endl;
    return BackendType::ONNX_RUNTIME;
}

// 4. Preprocess Image
cv::Mat LoFTR_Interface::preprocessImage(const cv::Mat& img) {
    cv::Mat processed;
    
    // Convert to grayscale image
    if (img.channels() == 3) {
        cv::cvtColor(img, processed, cv::COLOR_BGR2GRAY);
    } else {
        processed = img.clone();
    }
    
    // Adjust the size
    if (processed.size() != network_input_size_) {
        cv::resize(processed, processed, network_input_size_);
        
        // Caculate the scale factor (for the cooderinate transfer)
        scale_factor_ = std::max(
            static_cast<float>(img.cols) / network_input_size_.width,
            static_cast<float>(img.rows) / network_input_size_.height
        );
    }
    
    // normalized 
    processed.convertTo(processed, CV_32F, 1.0/255.0);
    
    return processed;
}

// ğŸ”§ ä¿®å¤åçš„ postprocessMatches å‡½æ•°
LoFTR_Interface::MatchResult LoFTR_Interface::postprocessMatches(
    const std::vector<float>& raw_result, cv::Size img0_size, cv::Size img1_size) {
    
    MatchResult result;
    
    if (raw_result.empty()) {
        std::cout << "[LoFTR] è­¦å‘Š: åŸå§‹ç»“æœä¸ºç©º" << std::endl;
        return result;
    }
    
    try {
        // ğŸ”§ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„åˆ†è¾¨ç‡
        float threshold = config_.match_threshold;  // ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
        int feature_resolution = 8;  // LoFTRæ ‡å‡†åˆ†è¾¨ç‡æ˜¯16ï¼Œä¸æ˜¯8
        int input_height = config_.input_height;
        int input_width = config_.input_width;
        
        // è®¡ç®—ç‰¹å¾å›¾å°ºå¯¸
        int hw0_h = input_height / feature_resolution;  // 352/16 = 22
        int hw0_w = input_width / feature_resolution;   // 640/16 = 40
        int feature_num = hw0_h * hw0_w;  // 22*40 = 880

        int expected_size = feature_num * feature_num;
        
        std::cout << "[LoFTR] è¾“å…¥å›¾åƒå°ºå¯¸: " << input_width << "x" << input_height << std::endl;
        std::cout << "[LoFTR] ç‰¹å¾å›¾å°ºå¯¸: " << hw0_w << "x" << hw0_h 
                  << " (total: " << feature_num << ")" << std::endl;
        std::cout << "[LoFTR] æœŸæœ›çŸ©é˜µå¤§å°: " << expected_size 
                  << ", å®é™…å¤§å°: " << raw_result.size() << std::endl;
        
        if (raw_result.size() != expected_size) {
            std::cerr << "[LoFTR] è¾“å‡ºå¤§å°ä¸åŒ¹é…ï¼" << std::endl;
            return result;
        }
        
        // ğŸ”§ æœç´¢ confidence matrix ä¸­çš„é«˜å€¼åŒ¹é…
        std::vector<std::tuple<int, int, float>> matches;
        
        for (int i = 0; i < feature_num; ++i) {
            for (int j = 0; j < feature_num; ++j) {
                int idx = i * feature_num + j;
                float confidence = raw_result[idx];
                
                if (confidence > threshold) {
                    matches.emplace_back(i, j, confidence);
                }
            }
        }
        
        std::cout << "[LoFTR] æ‰¾åˆ° " << matches.size() 
                  << " ä¸ªå€™é€‰åŒ¹é… (é˜ˆå€¼: " << threshold << ")" << std::endl;
        
        if (matches.empty()) {
            std::cout << "[LoFTR] æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³é˜ˆå€¼çš„åŒ¹é…ç‚¹" << std::endl;
            return result;
        }
        
        // æŒ‰ç½®ä¿¡åº¦æ’åº
        std::sort(matches.begin(), matches.end(), 
                 [](const auto& a, const auto& b) { return std::get<2>(a) > std::get<2>(b); });
        
        // é™åˆ¶åŒ¹é…æ•°é‡
        int max_matches = std::min(static_cast<int>(matches.size()), config_.max_matches);
        
        // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„åæ ‡è½¬æ¢é€»è¾‘
        for (int m = 0; m < max_matches; ++m) {
            int i = std::get<0>(matches[m]);  // img0çš„ç‰¹å¾ç‚¹ç´¢å¼•
            int j = std::get<1>(matches[m]);  // img1çš„ç‰¹å¾ç‚¹ç´¢å¼•
            float confidence = std::get<2>(matches[m]);
            
            // *** å…³é”®ä¿®å¤ï¼šåˆ†åˆ«å¤„ç†ä¸¤å¼ å›¾ç‰‡çš„åæ ‡ ***
            
            // img0çš„ç‰¹å¾ç‚¹åæ ‡ï¼ˆiç´¢å¼•å¯¹åº”ï¼‰
            int grid_x0 = i % hw0_w;
            int grid_y0 = i / hw0_w;
            float network_x0 = grid_x0 * feature_resolution + feature_resolution / 2.0f;
            float network_y0 = grid_y0 * feature_resolution + feature_resolution / 2.0f;
            
            // img1çš„ç‰¹å¾ç‚¹åæ ‡ï¼ˆjç´¢å¼•å¯¹åº”ï¼‰
            int grid_x1 = j % hw0_w;
            int grid_y1 = j / hw0_w;
            float network_x1 = grid_x1 * feature_resolution + feature_resolution / 2.0f;
            float network_y1 = grid_y1 * feature_resolution + feature_resolution / 2.0f;
            
            // è½¬æ¢ä¸ºåŸå§‹å›¾åƒåæ ‡
            float final_x0 = network_x0 * img0_size.width / input_width;
            float final_y0 = network_y0 * img0_size.height / input_height;
            float final_x1 = network_x1 * img1_size.width / input_width;
            float final_y1 = network_y1 * img1_size.height / input_height;
            
            // è°ƒè¯•å‰å‡ ä¸ªåŒ¹é…ç‚¹çš„åæ ‡è½¬æ¢
            if (m < 3) {
                std::cout << "[LoFTR] Match " << m << ": "
                          << "grid0(" << grid_x0 << "," << grid_y0 << ") -> img0(" << final_x0 << "," << final_y0 << "), "
                          << "grid1(" << grid_x1 << "," << grid_y1 << ") -> img1(" << final_x1 << "," << final_y1 << "), "
                          << "conf=" << confidence << std::endl;
            }
            
            // æ£€æŸ¥åæ ‡æœ‰æ•ˆæ€§
            if (final_x0 >= 0 && final_x0 < img0_size.width &&
                final_y0 >= 0 && final_y0 < img0_size.height &&
                final_x1 >= 0 && final_x1 < img1_size.width &&
                final_y1 >= 0 && final_y1 < img1_size.height) {
                
                result.keypoints0.emplace_back(final_x0, final_y0);
                result.keypoints1.emplace_back(final_x1, final_y1);
                result.confidence.push_back(confidence);
            }
        }
        
        result.num_matches = result.keypoints0.size();
        
        std::cout << "[LoFTR] æœ€ç»ˆæœ‰æ•ˆåŒ¹é…: " << result.num_matches << std::endl;
        
        if (result.num_matches > 0) {
            // æ˜¾ç¤ºåæ ‡èŒƒå›´ä»¥éªŒè¯ä¿®å¤æ•ˆæœ
            auto [min_x0, max_x0] = std::minmax_element(result.keypoints0.begin(), result.keypoints0.end(),
                [](const cv::Point2f& a, const cv::Point2f& b) { return a.x < b.x; });
            auto [min_y0, max_y0] = std::minmax_element(result.keypoints0.begin(), result.keypoints0.end(),
                [](const cv::Point2f& a, const cv::Point2f& b) { return a.y < b.y; });
                
            auto [min_x1, max_x1] = std::minmax_element(result.keypoints1.begin(), result.keypoints1.end(),
                [](const cv::Point2f& a, const cv::Point2f& b) { return a.x < b.x; });
            auto [min_y1, max_y1] = std::minmax_element(result.keypoints1.begin(), result.keypoints1.end(),
                [](const cv::Point2f& a, const cv::Point2f& b) { return a.y < b.y; });
            
            std::cout << "[LoFTR] img0åæ ‡èŒƒå›´: x=[" << min_x0->x << ", " << max_x0->x 
                      << "], y=[" << min_y0->y << ", " << max_y0->y << "]" << std::endl;
            std::cout << "[LoFTR] img1åæ ‡èŒƒå›´: x=[" << min_x1->x << ", " << max_x1->x 
                      << "], y=[" << min_y1->y << ", " << max_y1->y << "]" << std::endl;
            
            if (!result.confidence.empty()) {
                float min_conf = *std::min_element(result.confidence.begin(), result.confidence.end());
                float max_conf = *std::max_element(result.confidence.begin(), result.confidence.end());
                std::cout << "[LoFTR] ç½®ä¿¡åº¦èŒƒå›´: " << min_conf << " - " << max_conf << std::endl;
            }
        }
        
    } catch (const std::exception& e) {
        std::cerr << "[LoFTR] åå¤„ç†å¼‚å¸¸: " << e.what() << std::endl;
    }
    
    return result;
}

std::vector<cv::Point2f> LoFTR_Interface::rescalePoints(
    const std::vector<cv::Point2f>& points, cv::Size network_size, cv::Size original_size) {
    
    std::vector<cv::Point2f> rescaled_points;
    rescaled_points.reserve(points.size());
    
    float scale_x = static_cast<float>(original_size.width) / network_size.width;
    float scale_y = static_cast<float>(original_size.height) / network_size.height;
    
    for (const auto& pt : points) {
        rescaled_points.emplace_back(pt.x * scale_x, pt.y * scale_y);
    }
    
    return rescaled_points;
}

std::string LoFTR_Interface::getBackendInfo() const {
    switch (active_backend_) {
        case BackendType::TENSORRT:
            return "TensorRT";
        case BackendType::ONNX_RUNTIME:
            return "ONNX Runtime";
        case BackendType::AUTO:
            return "AUTO (not selected)";
        default:
            return "Unknown";
    }
}

double LoFTR_Interface::getAverageInferenceTime() const {
    if (inference_times_.empty()) {
        return 0.0;
    }
    
    double sum = 0.0;
    for (double time : inference_times_) {
        sum += time;
    }
    return sum / inference_times_.size();
}

void LoFTR_Interface::resetStats() {
    inference_times_.clear();
    total_matches_ = 0;
}

// LoFTR_Utils å®ç°
namespace LoFTR_Utils {

// 6. Visualized function
cv::Mat visualizeMatches(const cv::Mat& img0, const cv::Mat& img1,
                        const LoFTR_Interface::MatchResult& result,
                        bool show_lines) {
    // åˆ›å»ºå¹¶æ’æ˜¾ç¤ºçš„å›¾åƒ
    cv::Mat vis_img;
    cv::hconcat(img0, img1, vis_img);
    
    // è½¬æ¢ä¸ºå½©è‰²å›¾åƒï¼ˆå¦‚æœéœ€è¦ï¼‰
    if (vis_img.channels() == 1) {
        cv::cvtColor(vis_img, vis_img, cv::COLOR_GRAY2BGR);
    }
    
    int img0_width = img0.cols;
    
    // ç»˜åˆ¶å…³é”®ç‚¹å’ŒåŒ¹é…çº¿
    for (size_t i = 0; i < result.keypoints0.size(); ++i) {
        cv::Point2f pt0 = result.keypoints0[i];
        cv::Point2f pt1 = result.keypoints1[i];
        pt1.x += img0_width; // è°ƒæ•´å³å›¾çš„ x åæ ‡
        
        // æ ¹æ®ç½®ä¿¡åº¦ç¡®å®šé¢œè‰²
        float conf = result.confidence.empty() ? 1.0f : result.confidence[i];
        cv::Scalar color(0, 255 * conf, 255 * (1 - conf)); // ç»¿è‰²åˆ°çº¢è‰²
        
        // ç»˜åˆ¶å…³é”®ç‚¹
        cv::circle(vis_img, pt0, 3, color, -1);
        cv::circle(vis_img, pt1, 3, color, -1);
        
        // ç»˜åˆ¶è¿æ¥çº¿
        if (show_lines) {
            cv::line(vis_img, pt0, pt1, color, 1);
        }
    }
    
    // æ·»åŠ ä¿¡æ¯æ–‡æœ¬
    std::string info = "Matches: " + std::to_string(result.num_matches) + 
                      " | Time: " + std::to_string(static_cast<int>(result.inference_time_ms)) + "ms";
    cv::putText(vis_img, info, cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(255, 255, 255), 2);
    
    return vis_img;
}

// 7. File I/O
bool saveMatchesToFile(const LoFTR_Interface::MatchResult& result, const std::string& filename) {
    std::ofstream file(filename);
    if (!file.is_open()) {
        return false;
    }
    
    file << "# LoFTR Match Results\n";
    file << "# Format: x0 y0 x1 y1 confidence\n";
    file << "# Matches: " << result.num_matches << "\n";
    file << "# Inference time: " << result.inference_time_ms << " ms\n";
    
    for (size_t i = 0; i < result.keypoints0.size(); ++i) {
        file << result.keypoints0[i].x << " " << result.keypoints0[i].y << " "
             << result.keypoints1[i].x << " " << result.keypoints1[i].y << " ";
        
        if (!result.confidence.empty()) {
            file << result.confidence[i];
        } else {
            file << "1.0";
        }
        file << "\n";
    }
    
    return true;
}

LoFTR_Interface::MatchResult loadMatchesFromFile(const std::string& filename) {
    LoFTR_Interface::MatchResult result;
    std::ifstream file(filename);
    
    if (!file.is_open()) {
        return result;
    }
    
    std::string line;
    while (std::getline(file, line)) {
        if (line.empty() || line[0] == '#') {
            continue;
        }
        
        std::istringstream iss(line);
        float x0, y0, x1, y1, conf;
        if (iss >> x0 >> y0 >> x1 >> y1 >> conf) {
            result.keypoints0.emplace_back(x0, y0);
            result.keypoints1.emplace_back(x1, y1);
            result.confidence.push_back(conf);
        }
    }
    
    result.num_matches = result.keypoints0.size();
    return result;
}

double computeMatchQuality(const LoFTR_Interface::MatchResult& result) {
    if (result.confidence.empty()) {
        return 0.0;
    }
    
    double sum = 0.0;
    for (float conf : result.confidence) {
        sum += conf;
    }
    return sum / result.confidence.size();
}

} // namespace LoFTR_Utils